PRISM
=====

Version: 4.4.beta
Date: Sat Oct 28 19:39:13 EDT 2017
Hostname: klyu
Memory limits: cudd=1g, java(heap)=910.5m
Command line: prism 4VA_timer.pm -pctl 'Rmin=? [F "done"]' -exportadv policy.txt -s -exportstates states.txt

Parsing model file "4VA_timer.pm"...

1 property:
(1) Rmin=? [ F "done" ]

Type:        MDP
Modules:     human uav ugv site_one site_two site_three site_four 
Variables:   h clock_h move_h a clock_a move_a g clock_g move_g s1 s2 s3 s4 

Building model...

Computing reachable states...

Reachability (BFS): 32 iterations in 1.91 seconds (average 0.059750, setup 0.00)

Time for model construction: 2.03 seconds.

Type:        MDP
States:      65625000 (1 initial)
Transitions: 242116625
Choices:     218764625

Transition matrix: 7254 nodes (4 terminal), 242116625 minterms, vars: 39r/39c/67nd

Exporting list of reachable states in plain text format to file "states.txt"...

---------------------------------------------------------------------

Model checking: Rmin=? [ F "done" ]

Warning: Disabling Prob1 since this is needed for adversary generation

Prob0A: 76 iterations in 31.87 seconds (average 0.419316, setup 0.00)

Prob1E: 77 iterations in 34.79 seconds (average 0.451792, setup 0.00)

Warning: PRISM hasn't checked for zero-reward loops.
Your minimum rewards may be too low...

goal = 105000, inf = 0, maybe = 65520000

Computing remaining rewards...
Engine: Sparse

Building sparse matrix (transitions)... [n=65625000, nc=218094000, nnz=241446000, k=19] [3.8 GB]
Building action information... [250.3 MB]
Building sparse matrix (transition rewards)... [n=65625000, nc=218094000, nnz=45630000, k=19] [1.6 GB]
Creating vector for state rewards... [500.7 MB]
Creating vector for inf... [500.7 MB]
Allocating iteration vectors... [2 x 500.7 MB]
Allocating adversary vector... [250.3 MB]
TOTAL: [7.8 GB]

Starting iterations...
Iteration 4: max relative diff=1.000000, 6.54 sec so far
Iteration 8: max relative diff=0.500000, 13.12 sec so far
Iteration 12: max relative diff=0.333333, 19.66 sec so far
Iteration 16: max relative diff=0.250000, 26.17 sec so far
Iteration 20: max relative diff=0.200000, 32.70 sec so far
Iteration 24: max relative diff=0.166667, 39.22 sec so far
Iteration 28: max relative diff=0.142857, 45.77 sec so far
Iteration 31: max relative diff=0.125000, 50.84 sec so far
Iteration 34: max relative diff=0.125000, 55.93 sec so far
Iteration 37: max relative diff=0.111111, 60.99 sec so far
Iteration 41: max relative diff=0.090909, 67.52 sec so far
Iteration 45: max relative diff=0.076923, 74.01 sec so far
Iteration 49: max relative diff=0.071429, 80.53 sec so far
Iteration 53: max relative diff=0.066667, 87.06 sec so far
Iteration 57: max relative diff=0.058824, 93.57 sec so far
Iteration 61: max relative diff=0.055556, 100.10 sec so far
Iteration 65: max relative diff=0.000002, 106.60 sec so far

Iterative method: 67 iterations in 191.83 seconds (average 2.074090, setup 52.86)

Adversary written to file "policy.txt".

Value in the initial state: 4.34375

Time for model checking: 260.905 seconds.

Result: 4.34375 (value in the initial state)

---------------------------------------------------------------------

Note: There were 2 warnings during computation.

